\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[brazil]{babel}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{geometry}
\geometry{margin=2.5cm}
\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=blue,urlcolor=blue}
\usepackage{enumerate}

% Definições de ambientes
\theoremstyle{definition}
\newtheorem{definicao}{Definição}[section]
\newtheorem{exemplo}{Exemplo}[section]
\theoremstyle{plain}
\newtheorem{observacao}{Observação}[section]

\title{Material Auxiliar - Unidade 2\\
\large Convergência Estocástica e Resultados Limite\\
\normalsize Explicações Detalhadas e Didáticas}
\author{Curso de Inferência Estatística}
\date{Outubro 2025}

\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Introdução}

Este material auxiliar complementa as notas de aula da Unidade 2, fornecendo explicações mais detalhadas e didáticas dos principais conceitos abordados. O objetivo é facilitar a compreensão dos teoremas de convergência e suas aplicações práticas.

\section{Notação O($\cdot$) e o($\cdot$) - Big O e Little o}

\subsection{Motivação e Intuição}

A notação $O(\cdot)$ e $o(\cdot)$ é fundamental para descrever o comportamento assintótico de sequências e funções. Intuitivamente:

\begin{itemize}
    \item \textbf{$a_n = O(b_n)$}: "$a_n$ cresce \emph{no máximo} tão rápido quanto $b_n$"
    \item \textbf{$a_n = o(b_n)$}: "$a_n$ cresce \emph{mais devagar} que $b_n$"
\end{itemize}

\subsection{Definições Formais}

\begin{definicao}[Big O para sequências]
Sejam $\{a_n, n \geq 1\}$ e $\{b_n, n \geq 1\}$ sequências de números reais. Dizemos que
\[
a_n = O(b_n) \quad \text{se e somente se} \quad \exists\, k > 0,\, n_0 \in \mathbb{N} : \left|\frac{a_n}{b_n}\right| \leq k, \quad \forall n \geq n_0
\]
Isto é, a razão $|a_n/b_n|$ é limitada para $n$ suficientemente grande.
\end{definicao}

\begin{definicao}[Little o para sequências]
Dizemos que
\[
a_n = o(b_n) \quad \text{se e somente se} \quad \lim_{n \to \infty} \frac{a_n}{b_n} = 0
\]
Isto é, $a_n$ é desprezível comparado a $b_n$ quando $n$ é grande.
\end{definicao}

\begin{exemplo}[Comparações Comuns]
\begin{enumerate}
    \item $10n^2 + n = O(n^2)$ porque $\frac{10n^2 + n}{n^2} = 10 + \frac{1}{n} \leq 11$ para $n \geq 1$
    
    \item $n = o(n^2)$ porque $\lim_{n \to \infty} \frac{n}{n^2} = \lim_{n \to \infty} \frac{1}{n} = 0$
    
    \item $\log(n) = o(n)$ porque $\lim_{n \to \infty} \frac{\log(n)}{n} = 0$
    
    \item $n^{1/2} = O(n)$ mas $n \neq O(n^{1/2})$
\end{enumerate}
\end{exemplo}

\subsection{Propriedades Importantes}

\begin{observacao}[Álgebra de O e o]
\begin{enumerate}
    \item Se $a_n = o(b_n)$, então $a_n = O(b_n)$ (mas a recíproca é falsa)
    
    \item Se $a_n = O(b_n)$ e $c_n = O(d_n)$, então:
    \begin{itemize}
        \item $a_n \cdot c_n = O(b_n \cdot d_n)$
        \item $a_n + c_n = O(\max\{|b_n|, |d_n|\})$
    \end{itemize}
    
    \item $O(1)$ significa limitado: $|a_n| \leq k$ para algum $k > 0$ e $n$ grande
    
    \item $o(1)$ significa que $a_n \to 0$
\end{enumerate}
\end{observacao}

\subsection{Aplicação em Séries de Taylor}

A notação $O(\cdot)$ é essencial para expressar aproximações via série de Taylor:

\begin{exemplo}[Série de Taylor]
Para uma função $F(x)$ derivável até ordem $n$ em torno de $x_0$:
\[
F(x) = \sum_{k=0}^{n} \frac{F^{(k)}(x_0)}{k!}(x - x_0)^k + o\left((x - x_0)^n\right)
\]
quando $x \to x_0$.

Por exemplo:
\begin{itemize}
    \item $e^x = 1 + x + \frac{x^2}{2} + O(x^3)$ quando $x \to 0$
    \item $\log(1+x) = x - \frac{x^2}{2} + O(x^3)$ quando $x \to 0$
\end{itemize}
\end{exemplo}

\section{Convergência em Probabilidade}

\subsection{Intuição e Definição}

A convergência em probabilidade expressa a ideia de que, à medida que $n$ cresce, a probabilidade de $U_n$ estar "longe" de $u$ torna-se arbitrariamente pequena.

\begin{definicao}[Convergência em Probabilidade]
Uma sequência de variáveis aleatórias $\{U_n, n \geq 1\}$ converge em probabilidade para um número $u$ se
\[
P\left(|U_n - u| \geq \varepsilon\right) \xrightarrow{n \to \infty} 0, \quad \forall\, \varepsilon > 0
\]
Notação: $U_n \xrightarrow{P} u$
\end{definicao}

\subsection{Interpretação Prática}

Pense em $U_n$ como uma estimativa de $u$ baseada em $n$ observações. Convergência em probabilidade significa que:
\begin{itemize}
    \item Com $n$ grande, é \emph{altamente improvável} que $U_n$ esteja longe de $u$
    \item Para qualquer margem de erro $\varepsilon > 0$ que você escolha, a probabilidade de erro pode ser tornada arbitrariamente pequena aumentando $n$
\end{itemize}

\begin{exemplo}[Média Amostral]
Se $X_1, X_2, \ldots$ são v.a.'s i.i.d. com $E[X_i] = \mu$ e $\text{Var}(X_i) = \sigma^2 < \infty$, então
\[
\bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i \xrightarrow{P} \mu
\]
Isso significa que a média amostral converge para a média populacional.
\end{exemplo}

\subsection{Métodos para Provar Convergência em Probabilidade}

\begin{enumerate}
    \item \textbf{Desigualdade de Chebyshev:} Se $E[U_n] \to u$ e $\text{Var}(U_n) \to 0$, então $U_n \xrightarrow{P} u$
    
    \item \textbf{Convergência de momentos:} Se $E[|U_n - u|^r] \to 0$ para algum $r > 0$, então $U_n \xrightarrow{P} u$
    
    \item \textbf{Função geradora de momentos:} Se $M_{U_n}(t) \to e^{tu}$ para todo $t$, então $U_n \xrightarrow{P} u$
\end{enumerate}

\subsection{Propriedades Algébricas}

\begin{observacao}[Álgebra da Convergência em Probabilidade]
Se $U_n \xrightarrow{P} u$ e $V_n \xrightarrow{P} v$, então:
\begin{enumerate}
    \item $U_n + V_n \xrightarrow{P} u + v$
    \item $U_n \cdot V_n \xrightarrow{P} u \cdot v$
    \item $\frac{U_n}{V_n} \xrightarrow{P} \frac{u}{v}$ (se $P(V_n = 0) = 0$ e $v \neq 0$)
    \item Se $g(\cdot)$ é contínua, então $g(U_n) \xrightarrow{P} g(u)$
\end{enumerate}
\end{observacao}

\section{Convergência em Distribuição}

\subsection{Definição e Diferenças}

A convergência em distribuição é um conceito mais fraco que convergência em probabilidade.

\begin{definicao}[Convergência em Distribuição]
Uma sequência $\{U_n, n \geq 1\}$ com f.d.a. $F_n(u)$ converge em distribuição para uma v.a. $U$ com f.d.a. $F(u)$ se
\[
F_n(u) \xrightarrow{n \to \infty} F(u)
\]
em todos os pontos de continuidade de $F(\cdot)$.

Notação: $U_n \xrightarrow{D} U$
\end{definicao}

\subsection{Diferenças entre Convergências}

\begin{itemize}
    \item \textbf{Convergência em Probabilidade $\Rightarrow$ Convergência em Distribuição}
    
    \item \textbf{Convergência em Distribuição $\not\Rightarrow$ Convergência em Probabilidade} (em geral)
    
    \item \textbf{Exceção:} Se $U_n \xrightarrow{D} c$ (constante), então $U_n \xrightarrow{P} c$
\end{itemize}

\begin{exemplo}[Distinção Importante]
Considere $X \sim N(0,1)$ e defina $U_n = X$ para todo $n$. Então:
\begin{itemize}
    \item $U_n \xrightarrow{D} X$ (trivialmente, pois $F_n = F$ para todo $n$)
    \item $U_n \not\xrightarrow{P} X$ (não faz sentido: $U_n - X = 0$ sempre!)
\end{itemize}

Agora considere $U_n = (-1)^n X$:
\begin{itemize}
    \item $U_n \xrightarrow{D} X$ (ambos têm distribuição $N(0,1)$)
    \item $U_n \not\xrightarrow{P} X$ (pois $|U_n - X|$ não vai para zero)
\end{itemize}
\end{exemplo}

\subsection{Método da Função Geradora de Momentos}

Um método poderoso para provar convergência em distribuição:

\begin{observacao}[Teorema de Continuidade de Lévy]
Se $M_{U_n}(t) \to M_U(t)$ para todo $t$ em uma vizinhança de zero, então $U_n \xrightarrow{D} U$.
\end{observacao}

Este método é frequentemente usado nas provas do TCL.

\section{Lei Fraca dos Grandes Números}

\subsection{Versões e Interpretação}

A Lei Fraca dos Grandes Números (LFGN) é um dos resultados fundamentais da probabilidade.

\begin{observacao}[LFGN - Versão Simples]
Se $X_1, \ldots, X_n$ são v.a.'s i.i.d. com $E[X_i] = \mu < \infty$ e $\text{Var}(X_i) = \sigma^2 < \infty$, então
\[
\bar{X}_n \xrightarrow{P} \mu
\]
\end{observacao}

\begin{observacao}[LFGN de Khinchin]
A condição de variância finita pode ser relaxada: basta $E[X_i] = \mu < \infty$.
\end{observacao}

\subsection{Interpretação Prática}

\begin{itemize}
    \item A média amostral é um estimador \emph{consistente} da média populacional
    \item Quanto maior a amostra, mais confiável é a estimativa
    \item Justifica a "Lei dos Grandes Números" empírica: frequências relativas convergem para probabilidades
\end{itemize}

\begin{exemplo}[Lançamento de Moedas]
Se $X_i = 1$ (cara) ou $X_i = 0$ (coroa) com $P(X_i = 1) = p$, então
\[
\frac{\text{número de caras em } n \text{ lançamentos}}{n} = \bar{X}_n \xrightarrow{P} p
\]
\end{exemplo}

\subsection{Aplicações}

\begin{enumerate}
    \item \textbf{Estimação de parâmetros:} $\bar{X}_n$ estima $\mu$, $S_n^2$ estima $\sigma^2$
    
    \item \textbf{Simulação Monte Carlo:} Aproximar $E[g(X)]$ por $\frac{1}{n}\sum_{i=1}^n g(X_i)$
    
    \item \textbf{Testes de hipóteses:} Proporções amostrais convergem para proporções populacionais
\end{enumerate}

\section{Teorema Central do Limite}

\subsection{Enunciado e Importância}

O Teorema Central do Limite (TCL) é possivelmente o teorema mais importante da estatística.

\begin{observacao}[TCL - Versão Clássica]
Se $X_1, \ldots, X_n$ são v.a.'s i.i.d. com $E[X_i] = \mu$ e $\text{Var}(X_i) = \sigma^2 < \infty$, então
\[
\frac{\bar{X}_n - \mu}{\sigma/\sqrt{n}} = \frac{\sqrt{n}(\bar{X}_n - \mu)}{\sigma} \xrightarrow{D} N(0, 1)
\]
\end{observacao}

\subsection{Por Que é Tão Importante?}

\begin{enumerate}
    \item \textbf{Universalidade:} Funciona para \emph{qualquer} distribuição com variância finita
    
    \item \textbf{Base para inferência:} Justifica o uso da distribuição normal em intervalos de confiança e testes
    
    \item \textbf{Aproximação prática:} Com $n$ moderadamente grande ($n \geq 30$), $\bar{X}_n$ tem distribuição aproximadamente normal
\end{enumerate}

\subsection{Interpretação Geométrica}

O TCL diz que:
\begin{itemize}
    \item A distribuição de $\bar{X}_n$ fica mais concentrada em torno de $\mu$ (taxa $1/\sqrt{n}$)
    \item A forma da distribuição de $\frac{\bar{X}_n - \mu}{\sigma/\sqrt{n}}$ converge para a curva normal
    \item Não importa a distribuição original dos $X_i$!
\end{itemize}

\begin{exemplo}[Distribuição Uniforme]
Se $X_i \sim U(0,1)$ (distribuição uniforme), então $E[X_i] = 1/2$ e $\text{Var}(X_i) = 1/12$.
\[
\frac{\bar{X}_n - 1/2}{\sqrt{1/(12n)}} = \sqrt{12n}\left(\bar{X}_n - \frac{1}{2}\right) \xrightarrow{D} N(0,1)
\]
Embora $X_i$ seja uniforme (nada parecido com normal), $\bar{X}_n$ tem distribuição aproximadamente $N(1/2, 1/(12n))$ para $n$ grande.
\end{exemplo}

\subsection{Versões Padronizadas}

\begin{itemize}
    \item \textbf{$\sigma$ conhecido:} $Z_n = \frac{\sqrt{n}(\bar{X}_n - \mu)}{\sigma} \xrightarrow{D} N(0,1)$
    
    \item \textbf{$\sigma$ desconhecido:} $T_n = \frac{\sqrt{n}(\bar{X}_n - \mu)}{S_n} \xrightarrow{D} N(0,1)$
    
    (onde $S_n$ é o desvio padrão amostral)
\end{itemize}

\section{Teorema de Slutsky}

\subsection{Enunciado e Utilidade}

O Teorema de Slutsky permite combinar convergências de tipos diferentes.

\begin{observacao}[Teorema de Slutsky]
Se $U_n \xrightarrow{D} U$ e $V_n \xrightarrow{P} c$ (constante), então:
\begin{enumerate}
    \item $U_n + V_n \xrightarrow{D} U + c$
    \item $U_n \cdot V_n \xrightarrow{D} c \cdot U$
    \item $\frac{U_n}{V_n} \xrightarrow{D} \frac{U}{c}$ (se $c \neq 0$)
\end{enumerate}
\end{observacao}

\subsection{Por Que é Útil?}

O teorema de Slutsky é crucial quando:
\begin{itemize}
    \item Temos uma convergência em distribuição mas precisamos fazer operações algébricas
    \item Queremos substituir parâmetros desconhecidos por estimadores consistentes
    \item Provamos distribuições assintóticas de estatísticas de teste
\end{itemize}

\begin{exemplo}[Substituição do Desvio Padrão]
Pelo TCL: $\frac{\sqrt{n}(\bar{X}_n - \mu)}{\sigma} \xrightarrow{D} N(0,1)$

Como $S_n \xrightarrow{P} \sigma$, pelo Slutsky:
\[
\frac{\sqrt{n}(\bar{X}_n - \mu)}{S_n} = \frac{\sqrt{n}(\bar{X}_n - \mu)}{\sigma} \cdot \frac{\sigma}{S_n} \xrightarrow{D} N(0,1) \cdot 1 = N(0,1)
\]
Isso justifica usar $S_n$ quando $\sigma$ é desconhecido!
\end{exemplo}

\subsection{Aplicação em Testes de Hipóteses}

O teorema de Slutsky permite construir estatísticas de teste quando parâmetros são desconhecidos, substituindo-os por estimadores consistentes sem alterar a distribuição assintótica.

\section{Teorema de Mann-Wald (Método Delta)}

\subsection{Enunciado}

O Método Delta é uma ferramenta para encontrar a distribuição assintótica de transformações de estimadores.

\begin{observacao}[Teorema de Mann-Wald]
Se $\sqrt{n}(T_n - \theta) \xrightarrow{D} N(0, \sigma^2(\theta))$ e $g(\cdot)$ é uma função diferenciável com $g'(\theta) \neq 0$, então
\[
\sqrt{n}\left[g(T_n) - g(\theta)\right] \xrightarrow{D} N\left(0, \sigma^2(\theta) \cdot [g'(\theta)]^2\right)
\]
\end{observacao}

\subsection{Interpretação}

O método delta diz que:
\begin{itemize}
    \item Se $T_n$ é aproximadamente normal com taxa $1/\sqrt{n}$
    \item Então $g(T_n)$ também é aproximadamente normal com taxa $1/\sqrt{n}$
    \item A variância é "inflada" por $[g'(\theta)]^2$
\end{itemize}

\subsection{Ideia da Prova}

A prova usa aproximação de Taylor de primeira ordem:
\[
g(T_n) \approx g(\theta) + g'(\theta)(T_n - \theta)
\]
Multiplicando por $\sqrt{n}$:
\[
\sqrt{n}[g(T_n) - g(\theta)] \approx g'(\theta) \cdot \sqrt{n}(T_n - \theta)
\]
Como $\sqrt{n}(T_n - \theta) \xrightarrow{D} N(0, \sigma^2)$, o resultado segue.

\begin{exemplo}[Transformação Logarítmica]
Se $\bar{X}_n$ estima $\mu > 0$ e queremos estimar $\log(\mu)$, tome $g(x) = \log(x)$.

Como $g'(x) = 1/x$, temos:
\[
\sqrt{n}\left[\log(\bar{X}_n) - \log(\mu)\right] \xrightarrow{D} N\left(0, \frac{\sigma^2}{\mu^2}\right)
\]
\end{exemplo}

\begin{exemplo}[Transformação de Variância]
Para estimar a variância $\sigma^2$, usamos $S_n^2$. Se queremos estimar o desvio padrão $\sigma = \sqrt{\sigma^2}$, usamos $g(x) = \sqrt{x}$ com $g'(x) = \frac{1}{2\sqrt{x}}$.
\end{exemplo}

\subsection{Aplicações Práticas}

\begin{enumerate}
    \item \textbf{Transformações estabilizadoras de variância}
    \item \textbf{Intervalos de confiança para funções de parâmetros}
    \item \textbf{Testes de hipóteses sobre transformações}
    \item \textbf{Modelos não-lineares}
\end{enumerate}

\section{Teorema Central do Limite para Variância Amostral}

\subsection{Motivação}

Enquanto o TCL clássico trata da distribuição assintótica de $\bar{X}_n$, é natural perguntar: qual a distribuição assintótica de $S_n^2$ (a variância amostral)?

\begin{observacao}[TCL para $S_n^2$]
Se $X_1, \ldots, X_n$ são v.a.'s i.i.d. com $E[X_i] = \mu$, $\text{Var}(X_i) = \sigma^2$, e $\mu_4 = E[(X_i - \mu)^4] < \infty$, então
\[
\sqrt{n}(S_n^2 - \sigma^2) \xrightarrow[n \to \infty]{d} N(0, \mu_4 - \sigma^4)
\]
\end{observacao}

\subsection{Interpretação}

\begin{itemize}
    \item A variância assintótica é $\mu_4 - \sigma^4$, que depende do quarto momento central
    \item Para distribuições simétricas, $\mu_4$ mede o "peso nas caudas"
    \item Distribuições com caudas pesadas têm $\mu_4$ maior, logo maior variabilidade em $S_n^2$
\end{itemize}

\subsection{Comparação com Normalidade}

Para $X_i \sim N(\mu, \sigma^2)$:
\begin{itemize}
    \item $\mu_4 = 3\sigma^4$, logo a variância assintótica é $3\sigma^4 - \sigma^4 = 2\sigma^4$
    \item Isto coincide com a variância exata de $\frac{(n-1)S_n^2}{\sigma^2} \sim \chi^2_{n-1}$
\end{itemize}

\subsection{Ideia da Prova}

A prova combina o TCL clássico com o Teorema de Slutsky:

\begin{enumerate}
    \item Defina $W_n = \frac{n-1}{n}S_n^2$ e $Y_i = (X_i - \mu)^2$
    
    \item Mostre que $W_n = \bar{Y}_n - (\bar{X}_n - \mu)^2$
    
    \item Aplique TCL a $\bar{Y}_n$: $\sqrt{n}(\bar{Y}_n - \sigma^2) \xrightarrow{d} N(0, \mu_4 - \sigma^4)$
    
    \item Note que $\sqrt{n}(\bar{X}_n - \mu)^2 \xrightarrow{P} 0$ (é de ordem $O_P(1/\sqrt{n})$)
    
    \item Use Slutsky para concluir sobre $W_n$, depois relate a $S_n^2$
\end{enumerate}

\subsection{Aplicação Prática}

Este teorema permite construir intervalos de confiança assintóticos para $\sigma^2$:
\[
IC_{1-\alpha}(\sigma^2) = S_n^2 \pm z_{\alpha/2} \cdot \frac{\sqrt{\mu_4 - \sigma^4}}{\sqrt{n}}
\]
onde $\mu_4$ pode ser estimado por $\frac{1}{n}\sum_{i=1}^n (X_i - \bar{X}_n)^4$.

\section{Estimadores Consistentes}

\subsection{Definição e Intuição}

Consistência é uma propriedade fundamental de estimadores que garante convergência para o parâmetro verdadeiro.

\begin{definicao}[Estimador Consistente]
Um estimador $T_n = T_n(X_1, \ldots, X_n)$ de $\tau(\theta)$ é \textbf{consistente} (no sentido fraco) se
\[
T_n \xrightarrow[n \to \infty]{P} \tau(\theta), \quad \forall\, \theta \in \Theta
\]
\end{definicao}

\subsection{Interpretação Prática}

Um estimador consistente significa que:
\begin{itemize}
    \item Com amostras grandes, a probabilidade de erro significativo torna-se desprezível
    \item É um requisito mínimo para que um estimador seja considerado "bom"
    \item Diferente de não-viesamento (propriedade de amostra finita), consistência é assintótica
\end{itemize}

\subsection{Relação entre Viés, Variância e Consistência}

\begin{observacao}[Consistência via EQM]
Se $EQM_\theta[T_n] = E_\theta[(T_n - \tau(\theta))^2] \to 0$, então $T_n$ é consistente.

Como $EQM = \text{Viés}^2 + \text{Variância}$, temos consistência quando:
\[
B_\theta^2[T_n] \to 0 \quad \text{e} \quad \text{Var}_\theta[T_n] \to 0
\]
\end{observacao}

\begin{exemplo}[Estimadores Clássicos]
\begin{enumerate}
    \item $\bar{X}_n$ é consistente para $\mu$ (pela LFGN)
    \item $S_n^2 = \frac{1}{n-1}\sum_{i=1}^n (X_i - \bar{X}_n)^2$ é consistente para $\sigma^2$
    \item O EMV é geralmente consistente sob condições de regularidade
\end{enumerate}
\end{exemplo}

\subsection{Exemplo Detalhado: Máximo da Uniforme}

\begin{exemplo}[Consistência de $X_{n:n}$ para $U(0, \theta)$]
Se $X_1, \ldots, X_n \sim U(0, \theta)$, o EMV de $\theta$ é $\hat{\theta} = X_{n:n} = \max\{X_1, \ldots, X_n\}$.

A f.d.a. de $X_{n:n}$ é:
\[
F_{X_{n:n}}(t) = \begin{cases}
0, & t < 0 \\
(t/\theta)^n, & 0 \leq t \leq \theta \\
1, & t > \theta
\end{cases}
\]

Para $\varepsilon > 0$ com $\varepsilon < \theta$:
\begin{align}
P(|X_{n:n} - \theta| < \varepsilon) &= P(\theta - \varepsilon < X_{n:n} < \theta) \\
&= 1 - (\theta - \varepsilon)^n/\theta^n \\
&= 1 - (1 - \varepsilon/\theta)^n \to 1
\end{align}
quando $n \to \infty$.

Logo, $X_{n:n} \xrightarrow{P} \theta$.
\end{exemplo}

\subsection{Tamanho Amostral Mínimo}

Um aspecto prático interessante: dado $\varepsilon > 0$ e $\delta \in (0,1)$, qual o tamanho amostral mínimo $n_0$ para garantir
\[
P(|X_{n:n} - \theta| < \varepsilon) \geq 1 - \delta?
\]

Solução: De $1 - (1 - \varepsilon/\theta)^n \geq 1 - \delta$, obtemos
\[
n \geq \frac{\log \delta}{\log(1 - \varepsilon/\theta)}
\]

Assim:
\[
n_0 = \left\lceil \frac{\log \delta}{\log(1 - \varepsilon/\theta)} \right\rceil + 1
\]

\begin{exemplo}[Cálculo Numérico]
Para $\theta = 1$, $\varepsilon = 0.1$, $\delta = 0.05$:
\[
n_0 = \left\lceil \frac{\log(0.05)}{\log(0.9)} \right\rceil + 1 = \left\lceil \frac{-2.996}{-0.105} \right\rceil + 1 = 29
\]
Com 29 observações, temos 95\% de chance de $X_{n:n}$ estar a menos de 0.1 de $\theta = 1$.
\end{exemplo}

\section{Propriedades Assintóticas dos Estimadores de Máxima Verossimilhança}

\subsection{Introdução}

Os EMVs possuem propriedades assintóticas excepcionais que justificam sua popularidade na prática estatística.

\subsection{Eficiência Relativa Assintótica}

\begin{definicao}[Eficiência Relativa Assintótica]
Se dois estimadores $T_n^{(1)}$ e $T_n^{(2)}$ para $g(\theta)$ são assintoticamente normais:
\[
\sqrt{n}(T_n^{(i)} - g(\theta)) \xrightarrow[n \to \infty]{d} N(0, \sigma_i^2(\theta)), \quad i = 1, 2
\]
a eficiência relativa assintótica (ERA) de $T_n^{(2)}$ em relação a $T_n^{(1)}$ é:
\[
\text{ERA} = \frac{\sigma_1^2(\theta)}{\sigma_2^2(\theta)}
\]
\end{definicao}

\subsection{Interpretação}

\begin{itemize}
    \item ERA $> 1$: $T_n^{(2)}$ é mais eficiente (menor variância assintótica)
    \item ERA $= 1$: Ambos são igualmente eficientes
    \item ERA $< 1$: $T_n^{(1)}$ é mais eficiente
\end{itemize}

\subsection{Teorema Central do Limite para EMVs}

\begin{observacao}[TCL para EMVs]
Sob condições de regularidade, se $\hat{\theta}_n$ é o EMV de $\theta$, então:
\[
\sqrt{n}(\hat{\theta}_n - \theta) \xrightarrow[n \to \infty]{d} N(0, I_X^{-1}(\theta))
\]
onde $I_X(\theta)$ é a informação de Fisher:
\[
I_X(\theta) = E_\theta\left[\left(\frac{\partial \log f(X; \theta)}{\partial \theta}\right)^2\right]
\]
\end{observacao}

\subsection{Condições de Regularidade}

As condições necessárias incluem:

\begin{enumerate}
    \item \textbf{(A1) Diferenciabilidade:} $f(x; \theta)$ é três vezes diferenciável em $\theta$
    
    \item \textbf{(A2) Troca de derivação e integração:} É válido trocar $\frac{\partial}{\partial \theta}$ com $\int$
    
    \item \textbf{(A3) Informação de Fisher finita:} $0 < I_X(\theta) < \infty$
    
    \item \textbf{(A4) Dominação local:} A terceira derivada é dominada por função integrável
    
    \item \textbf{(A5) Existência de solução consistente:} A equação de verossimilhança tem solução $\hat{\theta}_n \xrightarrow{P} \theta$
\end{enumerate}

\subsection{Propriedades dos EMVs}

Sob as condições de regularidade, os EMVs são:

\begin{enumerate}
    \item \textbf{Consistentes:} $\hat{\theta}_n \xrightarrow{P} \theta$
    
    \item \textbf{Assintoticamente não-viesados:} $\lim_{n \to \infty} E[\hat{\theta}_n] = \theta$
    
    \item \textbf{Assintoticamente normais:} A distribuição converge para normal
    
    \item \textbf{Assintoticamente eficientes:} Atingem o limite inferior de Cramér-Rao assintótico
\end{enumerate}

\subsection{Limite Inferior de Cramér-Rao Assintótico}

Para qualquer estimador não-viesado $T_n$ de $\theta$:
\[
\text{Var}(T_n) \geq \frac{1}{n \cdot I_X(\theta)}
\]

Os EMVs atingem este limite assintoticamente!

\subsection{Aplicação Prática}

\begin{exemplo}[Intervalo de Confiança via EMV]
Se $\hat{\theta}_n$ é o EMV, um IC assintótico de nível $1-\alpha$ para $\theta$ é:
\[
IC_{1-\alpha}(\theta) = \hat{\theta}_n \pm z_{\alpha/2} \cdot \frac{1}{\sqrt{n \cdot I_X(\hat{\theta}_n)}}
\]
onde $I_X(\hat{\theta}_n)$ é a informação de Fisher avaliada em $\hat{\theta}_n$.
\end{exemplo}

\begin{exemplo}[Distribuição Normal]
Para $X_i \sim N(\mu, \sigma^2)$ com $\sigma^2$ conhecido:
\begin{itemize}
    \item EMV: $\hat{\mu}_n = \bar{X}_n$
    \item Informação de Fisher: $I_X(\mu) = 1/\sigma^2$
    \item Distribuição assintótica: $\sqrt{n}(\bar{X}_n - \mu) \sim N(0, \sigma^2)$
\end{itemize}

Neste caso, a distribuição assintótica coincide com a exata!
\end{exemplo}

\subsection{Vantagens e Limitações}

\textbf{Vantagens:}
\begin{itemize}
    \item Propriedades ótimas assintoticamente
    \item Princípio unificado para construir estimadores
    \item Aproximação normal facilita inferência
\end{itemize}

\textbf{Limitações:}
\begin{itemize}
    \item Requer condições de regularidade
    \item Propriedades são assintóticas (podem não valer para $n$ pequeno)
    \item Computação pode ser complexa (requer otimização numérica)
\end{itemize}

\section{Resumo e Conexões}

\subsection{Hierarquia das Convergências}

\[
\text{Convergência quase certa} \Rightarrow \text{Convergência em Probabilidade} \Rightarrow \text{Convergência em Distribuição}
\]

\subsection{Teoremas Principais e Suas Relações}

\begin{enumerate}
    \item \textbf{LFGN:} $\bar{X}_n \xrightarrow{P} \mu$ (onde está o valor)
    
    \item \textbf{TCL clássico:} $\frac{\sqrt{n}(\bar{X}_n - \mu)}{\sigma} \xrightarrow{D} N(0,1)$ (quão rápido chega lá e qual a forma da distribuição)
    
    \item \textbf{TCL para $S_n^2$:} $\sqrt{n}(S_n^2 - \sigma^2) \xrightarrow{d} N(0, \mu_4 - \sigma^4)$ (distribuição assintótica da variância amostral)
    
    \item \textbf{Slutsky:} Permite combinações algébricas de convergências diferentes
    
    \item \textbf{Método Delta:} Estende para transformações não-lineares
    
    \item \textbf{Consistência:} Propriedade fundamental de estimadores ($T_n \xrightarrow{P} \theta$)
    
    \item \textbf{TCL para EMVs:} Propriedades assintóticas ótimas dos estimadores de máxima verossimilhança
\end{enumerate}

\subsection{Estratégia de Resolução de Problemas}

\begin{enumerate}
    \item \textbf{Identificar o tipo de problema:}
    \begin{itemize}
        \item Convergência pontual? $\to$ Usar LFGN ou consistência
        \item Distribuição assintótica? $\to$ Usar TCL
        \item Variância/segunda ordem? $\to$ TCL para $S_n^2$
    \end{itemize}
    
    \item \textbf{Verificar condições:}
    \begin{itemize}
        \item Variáveis i.i.d.?
        \item Momentos necessários existem?
        \item Condições de regularidade satisfeitas?
    \end{itemize}
    
    \item \textbf{Aplicar teoremas apropriados:}
    \begin{itemize}
        \item Para médias: LFGN ou TCL clássico
        \item Para variâncias: TCL para $S_n^2$
        \item Para EMVs: TCL para EMVs
    \end{itemize}
    
    \item \textbf{Lidar com complicações:}
    \begin{itemize}
        \item Parâmetros desconhecidos? $\to$ Slutsky
        \item Transformações não-lineares? $\to$ Método Delta
        \item Múltiplas convergências? $\to$ Algebra de convergências
    \end{itemize}
    
    \item \textbf{Construir inferência:}
    \begin{itemize}
        \item Intervalos de confiança assintóticos
        \item Testes de hipóteses assintóticos
        \item Regiões de confiança
    \end{itemize}
\end{enumerate}

\subsection{Quadro Sinótico: Quando Usar Cada Teorema}

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Objetivo} & \textbf{Teorema} & \textbf{Condições} \\
\hline
Estimador consistente? & LFGN ou EQM $\to 0$ & Momentos finitos \\
\hline
Distribuição de $\bar{X}_n$? & TCL clássico & $E[X_i^2] < \infty$ \\
\hline
Distribuição de $S_n^2$? & TCL para $S_n^2$ & $E[X_i^4] < \infty$ \\
\hline
$\sigma$ desconhecido? & Slutsky & $S_n \xrightarrow{P} \sigma$ \\
\hline
Função $g(\bar{X}_n)$? & Método Delta & $g'(\mu) \neq 0$ \\
\hline
EMV? & TCL para EMVs & Regularidade \\
\hline
\end{tabular}
\end{center}

\subsection{Mensagem Final}

Este material auxiliar complementa as notas de aula, fornecendo:
\begin{itemize}
    \item Explicações detalhadas dos conceitos principais
    \item Interpretações práticas dos resultados teóricos
    \item Exemplos numéricos e aplicações
    \item Estratégias para resolução de problemas
\end{itemize}

Os teoremas de convergência formam a base da inferência estatística moderna. Compreendê-los profundamente permite:
\begin{itemize}
    \item Justificar procedimentos estatísticos comuns
    \item Desenvolver novos métodos para problemas específicos
    \item Avaliar propriedades de estimadores e testes
    \item Construir aproximações úteis para cálculos práticos
\end{itemize}

\textbf{Estude com atenção, pratique muito, e boa sorte!}

\end{document}

