\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[brazil]{babel}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{geometry}
\geometry{margin=2.5cm}
\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=blue,urlcolor=blue}
\usepackage{enumerate}

% Definições de ambientes
\theoremstyle{definition}
\newtheorem{definicao}{Definição}[section]
\newtheorem{exemplo}{Exemplo}[section]
\theoremstyle{plain}
\newtheorem{observacao}{Observação}[section]

\title{Material Auxiliar - Unidade 2\\
\large Convergência Estocástica e Resultados Limite\\
\normalsize Explicações Detalhadas e Didáticas}
\author{Curso de Inferência Estatística}
\date{Outubro 2025}

\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Introdução}

Este material auxiliar complementa as notas de aula da Unidade 2, fornecendo explicações mais detalhadas e didáticas dos principais conceitos abordados. O objetivo é facilitar a compreensão dos teoremas de convergência e suas aplicações práticas.

\section{Notação O($\cdot$) e o($\cdot$) - Big O e Little o}

\subsection{Motivação e Intuição}

A notação $O(\cdot)$ e $o(\cdot)$ é fundamental para descrever o comportamento assintótico de sequências e funções. Intuitivamente:

\begin{itemize}
    \item \textbf{$a_n = O(b_n)$}: "$a_n$ cresce \emph{no máximo} tão rápido quanto $b_n$"
    \item \textbf{$a_n = o(b_n)$}: "$a_n$ cresce \emph{mais devagar} que $b_n$"
\end{itemize}

\subsection{Definições Formais}

\begin{definicao}[Big O para sequências]
Sejam $\{a_n, n \geq 1\}$ e $\{b_n, n \geq 1\}$ sequências de números reais. Dizemos que
\[
a_n = O(b_n) \quad \text{se e somente se} \quad \exists\, k > 0,\, n_0 \in \mathbb{N} : \left|\frac{a_n}{b_n}\right| \leq k, \quad \forall n \geq n_0
\]
Isto é, a razão $|a_n/b_n|$ é limitada para $n$ suficientemente grande.
\end{definicao}

\begin{definicao}[Little o para sequências]
Dizemos que
\[
a_n = o(b_n) \quad \text{se e somente se} \quad \lim_{n \to \infty} \frac{a_n}{b_n} = 0
\]
Isto é, $a_n$ é desprezível comparado a $b_n$ quando $n$ é grande.
\end{definicao}

\begin{exemplo}[Comparações Comuns]
\begin{enumerate}
    \item $10n^2 + n = O(n^2)$ porque $\frac{10n^2 + n}{n^2} = 10 + \frac{1}{n} \leq 11$ para $n \geq 1$
    
    \item $n = o(n^2)$ porque $\lim_{n \to \infty} \frac{n}{n^2} = \lim_{n \to \infty} \frac{1}{n} = 0$
    
    \item $\log(n) = o(n)$ porque $\lim_{n \to \infty} \frac{\log(n)}{n} = 0$
    
    \item $n^{1/2} = O(n)$ mas $n \neq O(n^{1/2})$
\end{enumerate}
\end{exemplo}

\subsection{Propriedades Importantes}

\begin{observacao}[Álgebra de O e o]
\begin{enumerate}
    \item Se $a_n = o(b_n)$, então $a_n = O(b_n)$ (mas a recíproca é falsa)
    
    \item Se $a_n = O(b_n)$ e $c_n = O(d_n)$, então:
    \begin{itemize}
        \item $a_n \cdot c_n = O(b_n \cdot d_n)$
        \item $a_n + c_n = O(\max\{|b_n|, |d_n|\})$
    \end{itemize}
    
    \item $O(1)$ significa limitado: $|a_n| \leq k$ para algum $k > 0$ e $n$ grande
    
    \item $o(1)$ significa que $a_n \to 0$
\end{enumerate}
\end{observacao}

\subsection{Aplicação em Séries de Taylor}

A notação $O(\cdot)$ é essencial para expressar aproximações via série de Taylor:

\begin{exemplo}[Série de Taylor]
Para uma função $F(x)$ derivável até ordem $n$ em torno de $x_0$:
\[
F(x) = \sum_{k=0}^{n} \frac{F^{(k)}(x_0)}{k!}(x - x_0)^k + o\left((x - x_0)^n\right)
\]
quando $x \to x_0$.

Por exemplo:
\begin{itemize}
    \item $e^x = 1 + x + \frac{x^2}{2} + O(x^3)$ quando $x \to 0$
    \item $\log(1+x) = x - \frac{x^2}{2} + O(x^3)$ quando $x \to 0$
\end{itemize}
\end{exemplo}

\section{Convergência em Probabilidade}

\subsection{Intuição e Definição}

A convergência em probabilidade expressa a ideia de que, à medida que $n$ cresce, a probabilidade de $U_n$ estar "longe" de $u$ torna-se arbitrariamente pequena.

\begin{definicao}[Convergência em Probabilidade]
Uma sequência de variáveis aleatórias $\{U_n, n \geq 1\}$ converge em probabilidade para um número $u$ se
\[
P\left(|U_n - u| \geq \varepsilon\right) \xrightarrow{n \to \infty} 0, \quad \forall\, \varepsilon > 0
\]
Notação: $U_n \xrightarrow{P} u$
\end{definicao}

\subsection{Interpretação Prática}

Pense em $U_n$ como uma estimativa de $u$ baseada em $n$ observações. Convergência em probabilidade significa que:
\begin{itemize}
    \item Com $n$ grande, é \emph{altamente improvável} que $U_n$ esteja longe de $u$
    \item Para qualquer margem de erro $\varepsilon > 0$ que você escolha, a probabilidade de erro pode ser tornada arbitrariamente pequena aumentando $n$
\end{itemize}

\begin{exemplo}[Média Amostral]
Se $X_1, X_2, \ldots$ são v.a.'s i.i.d. com $E[X_i] = \mu$ e $\text{Var}(X_i) = \sigma^2 < \infty$, então
\[
\bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i \xrightarrow{P} \mu
\]
Isso significa que a média amostral converge para a média populacional.
\end{exemplo}

\subsection{Métodos para Provar Convergência em Probabilidade}

\begin{enumerate}
    \item \textbf{Desigualdade de Chebyshev:} Se $E[U_n] \to u$ e $\text{Var}(U_n) \to 0$, então $U_n \xrightarrow{P} u$
    
    \item \textbf{Convergência de momentos:} Se $E[|U_n - u|^r] \to 0$ para algum $r > 0$, então $U_n \xrightarrow{P} u$
    
    \item \textbf{Função geradora de momentos:} Se $M_{U_n}(t) \to e^{tu}$ para todo $t$, então $U_n \xrightarrow{P} u$
\end{enumerate}

\subsection{Propriedades Algébricas}

\begin{observacao}[Álgebra da Convergência em Probabilidade]
Se $U_n \xrightarrow{P} u$ e $V_n \xrightarrow{P} v$, então:
\begin{enumerate}
    \item $U_n + V_n \xrightarrow{P} u + v$
    \item $U_n \cdot V_n \xrightarrow{P} u \cdot v$
    \item $\frac{U_n}{V_n} \xrightarrow{P} \frac{u}{v}$ (se $P(V_n = 0) = 0$ e $v \neq 0$)
    \item Se $g(\cdot)$ é contínua, então $g(U_n) \xrightarrow{P} g(u)$
\end{enumerate}
\end{observacao}

\section{Convergência em Distribuição}

\subsection{Definição e Diferenças}

A convergência em distribuição é um conceito mais fraco que convergência em probabilidade.

\begin{definicao}[Convergência em Distribuição]
Uma sequência $\{U_n, n \geq 1\}$ com f.d.a. $F_n(u)$ converge em distribuição para uma v.a. $U$ com f.d.a. $F(u)$ se
\[
F_n(u) \xrightarrow{n \to \infty} F(u)
\]
em todos os pontos de continuidade de $F(\cdot)$.

Notação: $U_n \xrightarrow{D} U$
\end{definicao}

\subsection{Diferenças entre Convergências}

\begin{itemize}
    \item \textbf{Convergência em Probabilidade $\Rightarrow$ Convergência em Distribuição}
    
    \item \textbf{Convergência em Distribuição $\not\Rightarrow$ Convergência em Probabilidade} (em geral)
    
    \item \textbf{Exceção:} Se $U_n \xrightarrow{D} c$ (constante), então $U_n \xrightarrow{P} c$
\end{itemize}

\begin{exemplo}[Distinção Importante]
Considere $X \sim N(0,1)$ e defina $U_n = X$ para todo $n$. Então:
\begin{itemize}
    \item $U_n \xrightarrow{D} X$ (trivialmente, pois $F_n = F$ para todo $n$)
    \item $U_n \not\xrightarrow{P} X$ (não faz sentido: $U_n - X = 0$ sempre!)
\end{itemize}

Agora considere $U_n = (-1)^n X$:
\begin{itemize}
    \item $U_n \xrightarrow{D} X$ (ambos têm distribuição $N(0,1)$)
    \item $U_n \not\xrightarrow{P} X$ (pois $|U_n - X|$ não vai para zero)
\end{itemize}
\end{exemplo}

\subsection{Método da Função Geradora de Momentos}

Um método poderoso para provar convergência em distribuição:

\begin{observacao}[Teorema de Continuidade de Lévy]
Se $M_{U_n}(t) \to M_U(t)$ para todo $t$ em uma vizinhança de zero, então $U_n \xrightarrow{D} U$.
\end{observacao}

Este método é frequentemente usado nas provas do TCL.

\section{Lei Fraca dos Grandes Números}

\subsection{Versões e Interpretação}

A Lei Fraca dos Grandes Números (LFGN) é um dos resultados fundamentais da probabilidade.

\begin{observacao}[LFGN - Versão Simples]
Se $X_1, \ldots, X_n$ são v.a.'s i.i.d. com $E[X_i] = \mu < \infty$ e $\text{Var}(X_i) = \sigma^2 < \infty$, então
\[
\bar{X}_n \xrightarrow{P} \mu
\]
\end{observacao}

\begin{observacao}[LFGN de Khinchin]
A condição de variância finita pode ser relaxada: basta $E[X_i] = \mu < \infty$.
\end{observacao}

\subsection{Interpretação Prática}

\begin{itemize}
    \item A média amostral é um estimador \emph{consistente} da média populacional
    \item Quanto maior a amostra, mais confiável é a estimativa
    \item Justifica a "Lei dos Grandes Números" empírica: frequências relativas convergem para probabilidades
\end{itemize}

\begin{exemplo}[Lançamento de Moedas]
Se $X_i = 1$ (cara) ou $X_i = 0$ (coroa) com $P(X_i = 1) = p$, então
\[
\frac{\text{número de caras em } n \text{ lançamentos}}{n} = \bar{X}_n \xrightarrow{P} p
\]
\end{exemplo}

\subsection{Aplicações}

\begin{enumerate}
    \item \textbf{Estimação de parâmetros:} $\bar{X}_n$ estima $\mu$, $S_n^2$ estima $\sigma^2$
    
    \item \textbf{Simulação Monte Carlo:} Aproximar $E[g(X)]$ por $\frac{1}{n}\sum_{i=1}^n g(X_i)$
    
    \item \textbf{Testes de hipóteses:} Proporções amostrais convergem para proporções populacionais
\end{enumerate}

\section{Teorema Central do Limite}

\subsection{Enunciado e Importância}

O Teorema Central do Limite (TCL) é possivelmente o teorema mais importante da estatística.

\begin{observacao}[TCL - Versão Clássica]
Se $X_1, \ldots, X_n$ são v.a.'s i.i.d. com $E[X_i] = \mu$ e $\text{Var}(X_i) = \sigma^2 < \infty$, então
\[
\frac{\bar{X}_n - \mu}{\sigma/\sqrt{n}} = \frac{\sqrt{n}(\bar{X}_n - \mu)}{\sigma} \xrightarrow{D} N(0, 1)
\]
\end{observacao}

\subsection{Por Que é Tão Importante?}

\begin{enumerate}
    \item \textbf{Universalidade:} Funciona para \emph{qualquer} distribuição com variância finita
    
    \item \textbf{Base para inferência:} Justifica o uso da distribuição normal em intervalos de confiança e testes
    
    \item \textbf{Aproximação prática:} Com $n$ moderadamente grande ($n \geq 30$), $\bar{X}_n$ tem distribuição aproximadamente normal
\end{enumerate}

\subsection{Interpretação Geométrica}

O TCL diz que:
\begin{itemize}
    \item A distribuição de $\bar{X}_n$ fica mais concentrada em torno de $\mu$ (taxa $1/\sqrt{n}$)
    \item A forma da distribuição de $\frac{\bar{X}_n - \mu}{\sigma/\sqrt{n}}$ converge para a curva normal
    \item Não importa a distribuição original dos $X_i$!
\end{itemize}

\begin{exemplo}[Distribuição Uniforme]
Se $X_i \sim U(0,1)$ (distribuição uniforme), então $E[X_i] = 1/2$ e $\text{Var}(X_i) = 1/12$.
\[
\frac{\bar{X}_n - 1/2}{\sqrt{1/(12n)}} = \sqrt{12n}\left(\bar{X}_n - \frac{1}{2}\right) \xrightarrow{D} N(0,1)
\]
Embora $X_i$ seja uniforme (nada parecido com normal), $\bar{X}_n$ tem distribuição aproximadamente $N(1/2, 1/(12n))$ para $n$ grande.
\end{exemplo}

\subsection{Versões Padronizadas}

\begin{itemize}
    \item \textbf{$\sigma$ conhecido:} $Z_n = \frac{\sqrt{n}(\bar{X}_n - \mu)}{\sigma} \xrightarrow{D} N(0,1)$
    
    \item \textbf{$\sigma$ desconhecido:} $T_n = \frac{\sqrt{n}(\bar{X}_n - \mu)}{S_n} \xrightarrow{D} N(0,1)$
    
    (onde $S_n$ é o desvio padrão amostral)
\end{itemize}

\section{Teorema de Slutsky}

\subsection{Enunciado e Utilidade}

O Teorema de Slutsky permite combinar convergências de tipos diferentes.

\begin{observacao}[Teorema de Slutsky]
Se $U_n \xrightarrow{D} U$ e $V_n \xrightarrow{P} c$ (constante), então:
\begin{enumerate}
    \item $U_n + V_n \xrightarrow{D} U + c$
    \item $U_n \cdot V_n \xrightarrow{D} c \cdot U$
    \item $\frac{U_n}{V_n} \xrightarrow{D} \frac{U}{c}$ (se $c \neq 0$)
\end{enumerate}
\end{observacao}

\subsection{Por Que é Útil?}

O teorema de Slutsky é crucial quando:
\begin{itemize}
    \item Temos uma convergência em distribuição mas precisamos fazer operações algébricas
    \item Queremos substituir parâmetros desconhecidos por estimadores consistentes
    \item Provamos distribuições assintóticas de estatísticas de teste
\end{itemize}

\begin{exemplo}[Substituição do Desvio Padrão]
Pelo TCL: $\frac{\sqrt{n}(\bar{X}_n - \mu)}{\sigma} \xrightarrow{D} N(0,1)$

Como $S_n \xrightarrow{P} \sigma$, pelo Slutsky:
\[
\frac{\sqrt{n}(\bar{X}_n - \mu)}{S_n} = \frac{\sqrt{n}(\bar{X}_n - \mu)}{\sigma} \cdot \frac{\sigma}{S_n} \xrightarrow{D} N(0,1) \cdot 1 = N(0,1)
\]
Isso justifica usar $S_n$ quando $\sigma$ é desconhecido!
\end{exemplo}

\subsection{Aplicação em Testes de Hipóteses}

O teorema de Slutsky permite construir estatísticas de teste quando parâmetros são desconhecidos, substituindo-os por estimadores consistentes sem alterar a distribuição assintótica.

\section{Teorema de Mann-Wald (Método Delta)}

\subsection{Enunciado}

O Método Delta é uma ferramenta para encontrar a distribuição assintótica de transformações de estimadores.

\begin{observacao}[Teorema de Mann-Wald]
Se $\sqrt{n}(T_n - \theta) \xrightarrow{D} N(0, \sigma^2(\theta))$ e $g(\cdot)$ é uma função diferenciável com $g'(\theta) \neq 0$, então
\[
\sqrt{n}\left[g(T_n) - g(\theta)\right] \xrightarrow{D} N\left(0, \sigma^2(\theta) \cdot [g'(\theta)]^2\right)
\]
\end{observacao}

\subsection{Interpretação}

O método delta diz que:
\begin{itemize}
    \item Se $T_n$ é aproximadamente normal com taxa $1/\sqrt{n}$
    \item Então $g(T_n)$ também é aproximadamente normal com taxa $1/\sqrt{n}$
    \item A variância é "inflada" por $[g'(\theta)]^2$
\end{itemize}

\subsection{Ideia da Prova}

A prova usa aproximação de Taylor de primeira ordem:
\[
g(T_n) \approx g(\theta) + g'(\theta)(T_n - \theta)
\]
Multiplicando por $\sqrt{n}$:
\[
\sqrt{n}[g(T_n) - g(\theta)] \approx g'(\theta) \cdot \sqrt{n}(T_n - \theta)
\]
Como $\sqrt{n}(T_n - \theta) \xrightarrow{D} N(0, \sigma^2)$, o resultado segue.

\begin{exemplo}[Transformação Logarítmica]
Se $\bar{X}_n$ estima $\mu > 0$ e queremos estimar $\log(\mu)$, tome $g(x) = \log(x)$.

Como $g'(x) = 1/x$, temos:
\[
\sqrt{n}\left[\log(\bar{X}_n) - \log(\mu)\right] \xrightarrow{D} N\left(0, \frac{\sigma^2}{\mu^2}\right)
\]
\end{exemplo}

\begin{exemplo}[Transformação de Variância]
Para estimar a variância $\sigma^2$, usamos $S_n^2$. Se queremos estimar o desvio padrão $\sigma = \sqrt{\sigma^2}$, usamos $g(x) = \sqrt{x}$ com $g'(x) = \frac{1}{2\sqrt{x}}$.
\end{exemplo}

\subsection{Aplicações Práticas}

\begin{enumerate}
    \item \textbf{Transformações estabilizadoras de variância}
    \item \textbf{Intervalos de confiança para funções de parâmetros}
    \item \textbf{Testes de hipóteses sobre transformações}
    \item \textbf{Modelos não-lineares}
\end{enumerate}

\section{Resumo e Conexões}

\subsection{Hierarquia das Convergências}

\[
\text{Convergência quase certa} \Rightarrow \text{Convergência em Probabilidade} \Rightarrow \text{Convergência em Distribuição}
\]

\subsection{Teoremas Principais e Suas Relações}

\begin{enumerate}
    \item \textbf{LFGN:} $\bar{X}_n \xrightarrow{P} \mu$ (onde está o valor)
    
    \item \textbf{TCL:} $\frac{\sqrt{n}(\bar{X}_n - \mu)}{\sigma} \xrightarrow{D} N(0,1)$ (quão rápido chega lá e qual a forma da distribuição)
    
    \item \textbf{Slutsky:} Permite combinações algébricas
    
    \item \textbf{Método Delta:} Estende para transformações não-lineares
\end{enumerate}

\subsection{Estratégia de Resolução de Problemas}

\begin{enumerate}
    \item Identificar se $T_n$ é uma média ou função de médias
    \item Aplicar LFGN ou TCL conforme apropriado
    \item Se há parâmetros desconhecidos, usar Slutsky para substituí-los
    \item Se há transformação não-linear, usar Método Delta
    \item Verificar condições (i.i.d., momentos finitos, etc.)
\end{enumerate}

\end{document}

